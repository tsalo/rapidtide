#!/usr/bin/env python
# -*- coding: latin-1 -*-
#
#   Copyright 2016-2019 Blaise Frederick
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
#
#       $Author: frederic $
#       $Date: 2016/06/14 12:04:51 $
#       $Id: showstxcorr,v 1.11 2016/06/14 12:04:51 frederic Exp $
#
from __future__ import print_function, division
import sys
import pandas as pd
import getopt
import rapidtide.miscmath as tide_math
import rapidtide.util as tide_util
import rapidtide.io as tide_io
import rapidtide.filter as tide_filt
import rapidtide.fit as tide_fit
import rapidtide.correlate as tide_corr
from scipy.stats.stats import pearsonr
import numpy as np
import nibabel as nib

from matplotlib.pyplot import plot, legend, show, figure


def getNullDistributionData(
    indata,
    xcorr_x,
    thefilter,
    windowfunc,
    detrendorder,
    searchstart,
    searchend,
    corrweighting="None",
    numreps=1000,
):
    print("estimating significance distribution using ", numreps, " repetitions")
    corrlist = np.zeros((numreps), dtype="float")
    corrlist_pear = np.zeros((numreps), dtype="float")
    xcorr_x_trim = xcorr_x[searchstart : searchend + 1]

    filteredindata = tide_math.corrnormalize(
        thefilter.apply(Fs, indata), windowfunc=windowfunc, detrendorder=detrendorder
    )
    for i in range(0, numreps):
        # make a shuffled copy of the regressors
        shuffleddata = np.random.permutation(indata)

        # filter it
        filteredshuffleddata = tide_math.corrnormalize(
            thefilter.apply(Fs, shuffleddata),
            windowfunc=windowfunc,
            detrendorder=detrendorder,
        )

        # crosscorrelate with original
        theshuffledxcorr = tide_corr.fastcorrelate(
            filteredindata,
            filteredshuffleddata,
            usefft=dofftcorr,
            weighting=corrweighting,
        )

        # find and tabulate correlation coefficient at optimal lag
        theshuffledxcorr_trim = theshuffledxcorr[searchstart : searchend + 1]
        maxdelay = xcorr_x_trim[np.argmax(theshuffledxcorr_trim)]
        corrlist[i] = theshuffledxcorr_trim[np.argmax(theshuffledxcorr_trim)]

        # find and tabulate correlation coefficient at 0 lag
        corrlist_pear[i] = pearsonr(filteredindata, filteredshuffleddata)[0]

        # progress
        tide_util.progressbar(i + 1, numreps, label="Percent complete")

    # jump to line after progress bar
    print()

    # return the distribution data
    return corrlist, corrlist_pear


def printthresholds(pcts, thepercentiles, labeltext):
    print(labeltext)
    for i in range(0, len(pcts)):
        print("\tp <", 1.0 - thepercentiles[i], ": ", pcts[i])


def _get_parser():
    parser = argparse.ArgumentParser(
        prog="showstxcorr",
        description="Plots the data in text files.",
        usage="%(prog)s texfilename[:col1,col2...,coln] [textfilename]... [options]",
    )

    parser.add_argument(
        "textfilenames",
        type=str,
        nargs="2",
        help="One or more input files, with optional column specifications",
    )

    parser.add_argument(
        "--outname",
        dest="outname",
        metavar="FILENAME",
        type=str,
        action="store",
        help="The root name of the output files.",
        default=None,
    )

    sampling = parser.add_mutually_exclusive_group()
    sampling.add_argument(
        "--samplerate",
        dest="samplerate",
        action="store",
        metavar="FREQ",
        type=lambda x: is_float(parser, x),
        help=(
            "Set the sample rate of the data file to FREQ. "
            "If neither samplerate or sampletime is specified, sample rate is 1.0."
        ),
        default="auto",
    )
    sampling.add_argument(
        "--sampletime",
        dest="samplerate",
        action="store",
        metavar="TSTEP",
        type=lambda x: invert_float(parser, x),
        help=(
            "Set the sample rate of the data file to 1.0/TSTEP. "
            "If neither samplerate or sampletime is specified, sample rate is 1.0."
        ),
        default="auto",
    )
    parser.add_argument(
        "--outname",
        dest="outname",
        metavar="FILENAME",
        type=str,
        action="store",
        help="The root name of the output files.",
        default=None,
    )

    return parser


def usage():
    print("")
    print(
        "showstxcorr - calculate and display the short term crosscorrelation between two timeseries"
    )
    print("")
    print(
        "usage: showstxcorr -i timecoursefile1 [-i timecoursefile2] --samplefreq=FREQ -o outputfile [-l LABEL] [-s STARTTIME] [-D DURATION] [-d] [-F LOWERFREQ,UPPERFREQ[,LOWERSTOP,UPPERSTOP]] [-V] [-L] [-R] [-C] [--nodetrend] [-nowindow] [-f] [--phat] [--liang] [--eckart] [-z FILENAME]"
    )
    print("")
    print("required arguments:")
    print(
        "    -i, --infile= timcoursefile1     - text file containing one or more timeseries"
    )
    print("    [-i, --infile= timcoursefile2]   - text file containing a timeseries")
    print(
        "                                       NB: if one timecourse file is specified, each column"
    )
    print(
        "                                       is considered a timecourse, and there must be at least"
    )
    print(
        "                                       2 columns in the file.  If two filenames are given, each"
    )
    print(
        "                                       file must have only one column of data."
    )
    print("")
    print("    -o, --outfile=OUTNAME:           - the root name of the output files")
    print("")
    print(
        "    --samplefreq=FREQ                - sample frequency of all timecourses is FREQ "
    )
    print("           or")
    print(
        "    --sampletime=TSTEP               - time step of all timecourses is TSTEP "
    )
    print(
        "                                       NB: --samplefreq and --sampletime are two ways to specify"
    )
    print("                                       the same thing.")
    print("")
    print("optional arguments:")
    print("    --nodetrend   - do not detrend the data before correlation")
    print("    --nowindow    - do not window data before corrlation")
    print("    --phat        - perform phase alignment transform (PHAT) rather than ")
    print("                    standard crosscorrelation")
    print(
        "    --liang       - perform phase alignment transform with Liang weighting function rather than "
    )
    print("                    standard crosscorrelation")
    print(
        "    --eckart      - perform phase alignment transform with Eckart weighting function rather than "
    )
    print("                    standard crosscorrelation")
    # print("    -l LABEL      - label for the delay value")
    print(
        "    -s STARTTIME  - time of first datapoint to use in seconds in the first file"
    )
    print("    -D DURATION   - amount of data to use in seconds")
    print("    -d            - turns off display of graph")
    print("    -F            - filter data and regressors from LOWERFREQ to UPPERFREQ.")
    print(
        "                    LOWERSTOP and UPPERSTOP can be specified, or will be calculated automatically"
    )
    print("    -V            - filter data and regressors to VLF band")
    print("    -L            - filter data and regressors to LFO band")
    print("    -R            - filter data and regressors to respiratory band")
    print("    -C            - filter data and regressors to cardiac band")
    # print("    -A            - print data on a single summary line")
    # print("    -a            - if summary mode is on, add a header line showing what values mean")
    # print("    -z FILENAME   - use the columns of FILENAME as controlling variables and return the partial correlation")
    print(
        "    -W WINDOWLEN  - use a window length of WINDOWLEN seconds (default is 50.0s)"
    )
    print(
        "    -S STEPSIZE   - timestep between subsequent measurements (default is 25.0s).  Will be rounded to the nearest sample time"
    )
    # print("    -N TRIALS     - estimate significance thresholds by Monte Carlo with TRIALS repetition")
    print("    -f            - negate second regressor")
    # print("    -i            - output intermediate steps in crosscorrelation calculation")
    print("")
    return ()


def main():
    # get the command line parameters
    searchrange = 15.0
    uselabel = False
    display = True
    corrweighting = "None"
    windowfunc = "hamming"
    detrendorder = 1
    dopartial = False
    duration = 1000000.0
    starttime = 0.0
    doplot = False
    thelabel = ""
    verbose = True
    summarymode = False
    labelline = False
    windowtime = 50.0
    window_lowestfreq = 1.0 / windowtime
    window_upperfreq = 0.15
    stepsize = 25.0
    estimate_significance = False
    flipregressor = False
    dumpfiltered = False
    matrixoutput = False

    # scan the command line arguments
    try:
        opts, args = getopt.gnu_getopt(
            sys.argv[1:],
            "i:IfN:W:S:z:aATtVLRCF:dl:s:D:wgo:",
            [
                "infile=",
                "outfile=",
                "phat",
                "liang",
                "eckart",
                "nodetrend",
                "nowindow",
                "samplefreq=",
                "sampletime=",
                "help",
            ],
        )
    except getopt.GetoptError as err:
        # print help information and exit:
        print(str(err))  # will print something like "option -x not recognized"
        usage()
        sys.exit(2)

    if len(args) > 1:
        print("showstxcorr takes no unflagged arguments")
        usage()
        exit()

    # unset all required arguments
    infilename = []
    sampletime = None
    Fs = None
    outfilename = None

    theprefilter = tide_filt.noncausalfilter()

    # set the default characteristics
    print("setting default filter to pass", window_lowestfreq, "to", window_upperfreq)
    theprefilter.settype("arb")
    theprefilter.setfreqs(
        window_lowestfreq,
        window_lowestfreq * 1.05,
        window_upperfreq / 1.05,
        window_upperfreq,
    )

    for o, a in opts:
        if o == "-d":
            display = False
            if verbose:
                print("disable display")
        elif o == "--infile" or o == "-i":
            infilename.append(a)
            if verbose:
                print("will use", infilename[-1], "as an input file")
        elif o == "--outfile" or o == "-o":
            outfilename = a
            if verbose:
                print("will use", outfilename, "as output file")
        elif o == "-T":
            trimdata = True
            if verbose:
                print("trimming data to match")
        elif o == "--samplefreq":
            Fs = float(a)
            sampletime = 1.0 / Fs
            linkchar = "="
            if verbose:
                print("Setting sample frequency to ", Fs)
        elif o == "--sampletime":
            sampletime = float(a)
            Fs = 1.0 / sampletime
            linkchar = "="
            if verbose:
                print("Setting sample time step to ", sampletime)
        elif o == "--liang":
            corrweighting = "Liang"
            if verbose:
                print("doing Liang weighted correlation")
        elif o == "--eckart":
            corrweighting = "Eckart"
            if verbose:
                print("doing Eckart weighted correlation")
        elif o == "--phat":
            corrweighting = "PHAT"
            if verbose:
                print("doing phase alignment transform")
        elif o == "-I":
            dumpfiltered = True
            if verbose:
                print("outputting intermediate calculations")
        elif o == "-f":
            flipregressor = True
            if verbose:
                print("negating second regressor")
        elif o == "-a":
            labelline = True
            if verbose:
                print("turning on label line")
        elif o == "-t":
            print(
                "DEPRECATION WARNING: detrending is now on by default.  Use --nodetrend to disable it"
            )
        elif o == "--nodetrend":
            detrendorder = 0
            if verbose:
                print("disabling detrending")
        elif o == "-w":
            print(
                "DEPRECATION WARNING: windowing is now on by default.  Use --nowindow to disable it"
            )
        elif o == "--nowindow":
            windowfunc = "None"
            if verbose:
                print("disabling windowing")
        elif o == "-z":
            controlvariablefile = a
            dopartial = True
            if verbose:
                print("performing partial correlations")
        elif o == "-l":
            thelabel = a
            uselabel = True
            if verbose:
                print("label set to", thelabel)
        elif o == "-D":
            duration = float(a)
            if verbose:
                print("duration set to", duration)
        elif o == "-W":
            windowtime = float(a)
            window_lowestfreq = 1.0 / windowtime
            theprefilter.settype("arb")
            theprefilter.setfreqs(
                window_lowestfreq,
                window_lowestfreq * 1.05,
                window_upperfreq / 1.05,
                window_upperfreq,
            )
            if verbose:
                print("windowtime set to", windowtime)
                print(
                    "setting default filter to pass",
                    window_lowestfreq,
                    "to",
                    window_upperfreq,
                )
        elif o == "-S":
            stepsize = sampletime * np.round(float(a) / sampletime)
            if verbose:
                print("stepsize set to", stepsize)
        elif o == "-N":
            numreps = int(a)
            estimate_significance = True
            if verbose:
                print("estimating significance threshold with ", numreps, " trials")
        elif o == "-s":
            starttime = float(a)
            if verbose:
                print("starttime set to", starttime)
        elif o == "-V":
            theprefilter.settype("vlf")
            if verbose:
                print("prefiltering to vlf band")
        elif o == "-L":
            theprefilter.settype("lfo")
            if verbose:
                print("prefiltering to lfo band")
        elif o == "-R":
            theprefilter.settype("resp")
            if verbose:
                print("prefiltering to respiratory band")
        elif o == "-C":
            theprefilter.settype("cardiac")
            if verbose:
                print("prefiltering to cardiac band")
        elif o == "-A":
            verbose = False
            summarymode = True
        elif o == "-F":
            arbvec = a.split(",")
            if len(arbvec) != 2 and len(arbvec) != 4:
                usage()
                sys.exit()
            if len(arbvec) == 2:
                arb_lower = float(arbvec[0])
                arb_upper = float(arbvec[1])
                arb_lowerstop = 0.9 * float(arbvec[0])
                arb_upperstop = 1.1 * float(arbvec[1])
            if len(arbvec) == 4:
                arb_lower = float(arbvec[0])
                arb_upper = float(arbvec[1])
                arb_lowerstop = float(arbvec[2])
                arb_upperstop = float(arbvec[3])
            theprefilter.settype("arb")
            theprefilter.setfreqs(arb_lowerstop, arb_lower, arb_upper, arb_upperstop)
            if verbose:
                print(
                    "prefiltering to ",
                    arb_lower,
                    arb_upper,
                    "(stops at ",
                    arb_lowerstop,
                    arb_upperstop,
                    ")",
                )
        else:
            assert False, "unhandled option"

    # check that required arguments are set
    if outfilename is None:
        print("outfile must be set")
        usage()
        sys.exit()

    if sampletime is None:
        print("sampletime must be set")
        usage()
        sys.exit()

    # read in the files and get everything trimmed to the right length
    stepsize = sampletime * np.round(stepsize / sampletime)
    startpoint = max([int(starttime * Fs), 0])
    if len(infilename) == 1:
        # each column is a timecourse, each row is a timepoint
        inputdata = tide_io.readvecs(infilename[0])
        print("input data shape is ", inputdata.shape)
        if inputdata.shape[0] > 2:
            matrixoutput = True
        numpoints = inputdata.shape[1]
        endpoint = min([startpoint + int(duration * Fs), numpoints])
        trimmeddata = inputdata[:, startpoint:endpoint]
    elif len(infilename) == 2:
        inputdata1 = tide_io.readvec(infilename[0])
        numpoints = len(inputdata1)
        inputdata2 = tide_io.readvec(infilename[1])
        endpoint1 = min(
            [
                startpoint + int(duration * Fs),
                int(len(inputdata1)),
                int(len(inputdata2)),
            ]
        )
        endpoint2 = min(
            [int(duration * Fs), int(len(inputdata1)), int(len(inputdata2))]
        )
        trimmeddata = np.zeros((2, numpoints), dtype="float")
        trimmeddata[0, :] = inputdata1[startpoint:endpoint1]
        trimmeddata[1, :] = inputdata2[0:endpoint2]
    else:
        print(
            "showstxcorr requires 1 multicolumn timecourse file or two single column timecourse files as input"
        )
        usage()
        sys.exit()

    # band limit the regressors if that is needed
    if theprefilter.gettype() != "None":
        if verbose:
            print("filtering to ", theprefilter.gettype(), " band")

    thedims = trimmeddata.shape
    tclen = thedims[1]
    numcomponents = thedims[0]
    reformdata = np.reshape(trimmeddata, (numcomponents, tclen))

    print("preprocessing all timecourses")
    for component in range(0, numcomponents):
        filtereddata = tide_math.corrnormalize(
            theprefilter.apply(Fs, reformdata[component, :]),
            windowfunc="None",
            detrendorder=detrendorder,
        )
        reformdata[component, :] = tide_math.stdnormalize(
            tide_fit.detrend(tide_math.stdnormalize(filtereddata), order=detrendorder)
        )

    xcorr_x = np.r_[0.0:tclen] * sampletime - (tclen * sampletime) / 2.0
    laglimit = 15.0
    widthlimit = 15.0
    halfwindow = int(laglimit * Fs)
    searchstart = int(int(tclen) // 2 - halfwindow)
    searchend = int(int(tclen) // 2 + halfwindow)
    xcorr_x_trim = xcorr_x[searchstart:searchend]
    if flipregressor:
        flipfac = -1.0
    else:
        flipfac = 1.0

    # now that we have all the information, we have a couple of places to go:
    # We are either doing short term correlations or full timecourse
    # We are either doing two time courses from different (or the same) files, or we are doing more than 2

    if matrixoutput:
        # find the lengths of the outputfiles
        print("finding timecourse lengths")
        times, corrpertime, ppertime = tide_corr.shorttermcorr_1D(
            reformdata[0, :],
            reformdata[0, :],
            sampletime,
            windowtime,
            samplestep=int(stepsize // sampletime),
            windowfunc=windowfunc,
            detrendorder=0,
        )
        plength = len(times)
        times, xcorrpertime, Rvals, delayvals, valid = tide_corr.shorttermcorr_2D(
            reformdata[0, :],
            reformdata[0, :],
            sampletime,
            windowtime,
            samplestep=int(stepsize // sampletime),
            weighting=corrweighting,
            windowfunc=windowfunc,
            detrendorder=0,
            display=False,
        )
        xlength = len(times)

        # now allocate the output arrays
        print("allocating data arrays")
        Rvals = np.zeros((numcomponents, numcomponents, 1, xlength), dtype="float")
        delayvals = np.zeros((numcomponents, numcomponents, 1, xlength), dtype="float")
        valid = np.zeros((numcomponents, numcomponents, 1, xlength), dtype="float")
        corrpertime = np.zeros(
            (numcomponents, numcomponents, 1, plength), dtype="float"
        )
        ppertime = np.zeros((numcomponents, numcomponents, 1, plength), dtype="float")

        # do the correlations
        for component1 in range(0, numcomponents):
            print("correlating with component", component1)
            for component2 in range(0, numcomponents):
                (
                    times,
                    corrpertime[component1, component2, 0, :],
                    ppertime[component1, component2, 0, :],
                ) = tide_corr.shorttermcorr_1D(
                    reformdata[component1, :],
                    flipfac * reformdata[component2, :],
                    sampletime,
                    windowtime,
                    samplestep=int(stepsize // sampletime),
                    windowfunc=windowfunc,
                    detrendorder=0,
                )
                (
                    times,
                    xcorrpertime,
                    Rvals[component1, component2, 0, :],
                    delayvals[component1, component2, 0, :],
                    valid[component1, component2, 0, :],
                ) = tide_corr.shorttermcorr_2D(
                    reformdata[component1, :],
                    flipfac * reformdata[component2, :],
                    sampletime,
                    windowtime,
                    samplestep=int(stepsize // sampletime),
                    weighting=corrweighting,
                    windowfunc=windowfunc,
                    detrendorder=0,
                    display=False,
                )

        outputaffine = np.eye(4)
        input_img, input_data, input_hdr, thedims, thesizes = tide_io.readfromnifti(
            inputfilename
        )
        init_img = nib.Nifti1Image(corrpertime, outputaffine)
        init_hdr = init_img.header.copy()
        init_sizes = init_hdr["pixdim"].copy()
        init_sizes[4] = sampletime
        init_hdr["toffset"] = times[0]
        tide_io.savetonifti(corrpertime, init_hdr, outfilename + "_pearsonR")
        tide_io.savetonifti(ppertime, init_hdr, outfilename + "_corrp")
        tide_io.savetonifti(Rvals, init_hdr, outfilename + "_maxxcorr")
        tide_io.savetonifti(delayvals, init_hdr, outfilename + "_delayvals")
        tide_io.savetonifti(valid, init_hdr, outfilename + "_valid")
        rows = []
        cols = []
        for i in range(numcomponents):
            rows.append("region " + str(i + 1))
            cols.append("region " + str(i + 1))
        for segment in range(plength):
            df = pd.DataFrame(data=corrpertime[:, :, 0, 0], columns=cols)
            df.insert(0, "sources", pd.Series(rows))
            df.to_csv(
                outfilename + "_seg_" + str(segment).zfill(4) + "_pearsonR.csv",
                index=False,
            )
            df = pd.DataFrame(data=ppertime[:, :, 0, 0], columns=cols)
            df.insert(0, "sources", pd.Series(rows))
            df.to_csv(
                outfilename + "_seg_" + str(segment).zfill(4) + "_corrp.csv",
                index=False,
            )
        for segment in range(xlength):
            df = pd.DataFrame(data=Rvals[:, :, 0, 0], columns=cols)
            df.insert(0, "sources", pd.Series(rows))
            df.to_csv(
                outfilename + "_seg_" + str(segment).zfill(4) + "_maxxcorr.csv",
                index=False,
            )
            df = pd.DataFrame(data=delayvals[:, :, 0, 0], columns=cols)
            df.insert(0, "sources", pd.Series(rows))
            df.to_csv(
                outfilename + "_seg_" + str(segment).zfill(4) + "_delayvals.csv",
                index=False,
            )
            df = pd.DataFrame(data=valid[:, :, 0, 0], columns=cols)
            df.insert(0, "sources", pd.Series(rows))
            df.to_csv(
                outfilename + "_seg_" + str(segment).zfill(4) + "_valid.csv",
                index=False,
            )

    else:
        times, corrpertime, ppertime = tide_corr.shorttermcorr_1D(
            reformdata[0, :],
            flipfac * reformdata[1, :],
            sampletime,
            windowtime,
            samplestep=int(stepsize // sampletime),
            windowfunc=windowfunc,
            detrendorder=0,
        )
        times, xcorrpertime, Rvals, delayvals, valid = tide_corr.shorttermcorr_2D(
            reformdata[0, :],
            flipfac * reformdata[1, :],
            sampletime,
            windowtime,
            samplestep=int(stepsize // sampletime),
            weighting=corrweighting,
            windowfunc=windowfunc,
            detrendorder=0,
            display=False,
        )
        tide_io.writenpvecs(corrpertime, outfilename + "_pearson.txt")
        tide_io.writenpvecs(ppertime, outfilename + "_pvalue.txt")
        tide_io.writenpvecs(Rvals, outfilename + "_Rvalue.txt")
        tide_io.writenpvecs(delayvals, outfilename + "_delay.txt")
        tide_io.writenpvecs(valid, outfilename + "_mask.txt")
        filtereddata1 = tide_math.corrnormalize(
            theprefilter.apply(Fs, trimmeddata[0, :]),
            windowfunc="None",
            detrendorder=detrendorder,
        )
        filtereddata2 = tide_math.corrnormalize(
            theprefilter.apply(Fs, trimmeddata[1, :]),
            windowfunc="None",
            detrendorder=detrendorder,
        )

    """
        if display:
            #timeaxis = np.r_[0.0:len(filtereddata1)] * sampletime
            fig, ax1 = plt.subplots()
            ax1.plot(times, corrpertime, 'k')
            ax1.set_ylabel('Pearson R', color='k')
            ax2 = ax1.twinx()
            ax2.plot(times, ppertime, 'r')
            ax2.set_ylabel('p value', color='r')
            fig, ax3 = plt.subplots()
            ax3.plot(times, Rvals, 'k')
            ax3.set_ylabel('Xcorr max R', color='k')
            ax4 = ax3.twinx()
            ax4.plot(times,delayvals, 'r')
            ax4.set_ylabel('Delay (s)', color='r')
            # ax2.set_yscale('log')
            plt.show()
    """


if __name__ == "__main__":
    main()
