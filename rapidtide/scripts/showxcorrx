#!/usr/bin/env python
# -*- coding: latin-1 -*-
#
#   Copyright 2016-2019 Blaise Frederick
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
#
# $Author: frederic $
#       $Date: 2016/07/11 14:50:43 $
#       $Id: showxcorr,v 1.41 2016/07/11 14:50:43 frederic Exp $
#
from __future__ import print_function, division

import sys
import os
import numpy as np
import scipy as sp

import argparse
import rapidtide.miscmath as tide_math
import rapidtide.stats as tide_stats
import rapidtide.io as tide_io
import rapidtide.peakeval as tide_peakeval
import rapidtide.fit as tide_fit
import rapidtide.correlate as tide_corr
import rapidtide.calcnullsimfunc as tide_nullsimfunc
import rapidtide.helper_classes as tide_classes

import rapidtide.workflows.parser_funcs as pf

from scipy.signal import correlate
from scipy.stats.stats import pearsonr

from matplotlib.pyplot import plot, legend, show, figure


def printthresholds(pcts, thepercentiles, labeltext):
    print(labeltext)
    for i in range(0, len(pcts)):
        print("\tp <", "{:.3f}".format(1.0 - thepercentiles[i]), ": ", pcts[i])


def usage(inputargs):
    print(
        os.path.basename(inputargs[0]),
        "- calculate and display crosscorrelation between two timeseries",
    )
    print("")
    print(
        "usage: ",
        os.path.basename(inputargs[0]),
        " timecourse1[:COLNUM] timecourse2[:COLNUM] samplerate",
    )
    print(
        " ".join(
            [
                "[-l LABEL]",
                "[-s STARTTIME]",
                "[-D DURATION]",
                "[-d]",
                "[-F LOWERFREQ,UPPERFREQ[,LOWERSTOP,UPPERSTOP]]",
                "[-V]",
                "[-L]",
                "[-R]",
                "[-C]",
                "[--nodetrend]",
                "[--nowindow]",
                "[-f]",
                "[-o OUTPUTFILE]",
                "[--phat]",
                "[--liang]",
                "[--eckart]",
                "[--savecorr=FILE]",
                "[-z FILENAME]",
                "[-N TRIALS]",
            ]
        )
    )
    print("")
    print("required arguments:")
    print(
        "    timcoursefile1[:COLNUM]: text file containing a timeseries.  Select column COLNUM if multicolumn file"
    )
    print(
        "    timcoursefile2[:COLNUM]: text file containing a timeseries.  Select column COLNUM if multicolumn file"
    )
    print("    samplerate:              sample rate of the timecourses, in Hz")
    print("")
    print("optional arguments:")
    print("    --nodetrend        - do not detrend the data before correlation")
    print("    --nowindow         - do not window data before corrlation")
    print(
        "    --windowfunc=FUNC  - window function to apply before corrlation (default is Hamming)"
    )
    print(
        "    --cepstral         - check time delay using Choudhary's cepstral technique "
    )
    print(
        "    --phat             - perform phase alignment transform (PHAT) rather than "
    )
    print("                         standard crosscorrelation")
    print(
        "    --liang            - perform phase alignment transform with Liang weighting function rather than "
    )
    print("                         standard crosscorrelation")
    print(
        "    --eckart           - perform phase alignment transform with Eckart weighting function rather than "
    )
    print("                         standard crosscorrelation")
    print("    -l LABEL           - label for the delay value")
    print(
        "    -s STARTTIME       - time of first datapoint to use in seconds in the first file"
    )
    print("    -D DURATION        - amount of data to use in seconds")
    print(
        "    -r RANGE           - restrict peak search range to +/- RANGE seconds (default is "
    )
    print("                         +/-15)")
    print("    -d                 - turns off display of graph")
    print(
        "    -F                 - filter data and regressors from LOWERFREQ to UPPERFREQ."
    )
    print(
        "                         LOWERSTOP and UPPERSTOP can be specified, or will be "
    )
    print("                         calculated automatically")
    print("    -V                 - filter data and regressors to VLF band")
    print("    -L                 - filter data and regressors to LFO band")
    print("    -R                 - filter data and regressors to respiratory band")
    print("    -C                 - filter data and regressors to cardiac band")
    print("    -T                 - trim data to match")

    print("    -A                 - print data on a single summary line")
    print(
        "    -a                 - if summary mode is on, add a header line showing what values "
    )
    print("                         mean")
    print("    -f                 - negate (flip) second regressor")
    print(
        "    -savecorr=FILE     - Save the correlation function to the file FILE in xy format"
    )
    print(
        "    -z FILENAME        - use the columns of FILENAME as controlling variables and "
    )
    print("                         return the partial correlation")
    print(
        "    -N TRIALS          - estimate significance thresholds by Monte Carlo with TRIALS "
    )
    print("                         repetition")
    print("    -o OUTPUTFILE      - Writes summary lines to OUTPUTFILE (sets -A)")
    print("")
    return ()


def _get_parser():
    """
    Argument parser for showxcorrx
    """
    parser = argparse.ArgumentParser(
        prog="showxcorrx",
        description=(
            "Calculate and display " "crosscorrelation between two " "timeseries."
        ),
        usage="%(prog)s infile1 infile2 samplerate [options]",
    )

    # Required arguments
    parser.add_argument(
        "infilename1",
        type=str,
        help="Text file containing a timeseries.  Select column COLNUM if multicolumn file",
    )
    parser.add_argument(
        "infilename2",
        type=str,
        help="Text file containing a timeseries.  Select column COLNUM if multicolumn file",
    )
    parser.add_argument(
        "samplerate",
        type=lambda x: pf.is_float(parser, x),
        help="Sample rate of the timecourses, in Hz",
    )

    # add optional arguments
    parser.add_argument(
        "--nodisplay",
        dest="display",
        action="store_false",
        help=("Do not plot the data (for noninteractive use)"),
        default=True,
    )
    parser.add_argument(
        "--debug",
        dest="debug",
        action="store_true",
        help=("Enable additional debugging output."),
        default=False,
    )
    parser.add_argument(
        "--verbose",
        dest="verbose",
        action="store_true",
        help=("Print out more debugging information"),
        default=False,
    )
    pf.addsearchrangeopts(parser, details=True)
    pf.addtimerangeopts(parser)
    parser.add_argument(
        "--trimdata",
        dest="trimdata",
        action="store_true",
        help=("Trimming data to match"),
        default=False,
    )

    preproc = parser.add_argument_group()
    preproc.add_argument(
        "--detrendorder",
        dest="detrendorder",
        action="store",
        type=int,
        metavar="ORDER",
        help=("Set order of trend removal (0 to disable, default is 1 - linear). "),
        default=1,
    )
    # add window options
    pf.addwindowopts(parser)

    # Filter arguments
    pf.addfilteropts(parser, "timecourses", details=True)

    # Preprocessing options
    preproc = parser.add_argument_group("Preprocessing options")
    preproc.add_argument(
        "--cepstral",
        dest="cepstral",
        action="store_true",
        help="Check time delay using Choudhary's cepstral technique. ",
        default=False,
    )
    preproc.add_argument(
        "--corrweighting",
        dest="corrweighting",
        action="store",
        type=str,
        choices=["None", "phat", "liang", "eckart"],
        help=("Method to use for cross-correlation " "weighting. Default is  None. "),
        default="None",
    )
    preproc.add_argument(
        "--invert",
        dest="invert",
        action="store_true",
        help=("Invert one timecourse prior to correlation. "),
        default=False,
    )
    preproc.add_argument(
        "--label",
        dest="label",
        metavar="LABEL",
        action="store",
        type=str,
        help=("Label for the delay value. "),
        default="None",
    )
    preproc.add_argument(
        "--partialcorr",
        dest="controlvariablefile",
        action="store",
        type=lambda x: pf.is_valid_file(parser, x),
        metavar="FILE",
        help=(
            "Use the columns of FILE as controlling variables and "
            "return the partial correlation. "
        ),
        default=None,
    )

    pf.addpermutationopts(preproc)

    # similarity function options
    similarityopts = parser.add_argument_group("Similarity function options")
    pf.addsimilarityopts(similarityopts)

    # Output options
    output = parser.add_argument_group("Output options")
    output.add_argument(
        "--outputfile",
        dest="outputfile",
        action="store",
        type=str,
        metavar="FILE",
        help=("Write results to FILE. "),
        default=None,
    )
    output.add_argument(
        "--corroutputfile",
        dest="corroutputfile",
        action="store",
        type=str,
        metavar="FILE",
        help=("Write correlation function to FILE. "),
        default=None,
    )
    output.add_argument(
        "--summarymode",
        dest="summarymode",
        action="store_true",
        help=("Print all results on a single line. "),
        default="False",
    )
    output.add_argument(
        "--labelline",
        dest="labelline",
        action="store_true",
        help=("Print a header line identifying fields in the summary line. "),
        default="False",
    )

    # Miscellaneous options
    misc = parser.add_argument_group("Miscellaneous options")
    misc.add_argument(
        "--noprogressbar",
        dest="showprogressbar",
        action="store_false",
        help="Will disable showing progress bars (helpful if stdout is going to a file). ",
        default=True,
    )
    misc.add_argument(
        "--nonorm",
        dest="minorm",
        action="store_false",
        help="Will disable normalization of the mutual information function. ",
        default=True,
    )
    misc.add_argument(
        "--nprocs",
        dest="nprocs",
        action="store",
        type=int,
        metavar="NPROCS",
        help=(
            "Use NPROCS worker processes for multiprocessing. "
            "Setting NPROCS to less than 1 sets the number of "
            "worker processes to n_cpus - 1. "
        ),
        default=1,
    )

    return parser


def main():
    # set some default values
    absmaxsigma = 1000.0
    absminsigma = 0.25
    zerooutbadfit = False
    peakfittype = "gauss"

    # grab the command line arguments then pass them off.
    try:
        args = _get_parser().parse_args()
    except SystemExit:
        _get_parser().print_help()
        raise

    # finish up processing arguments
    args, theprefilter = pf.postprocessfilteropts(args)
    args = pf.postprocesssearchrangeopts(args)
    args = pf.postprocesstimerangeopts(args)

    infilename1, colspec1 = tide_io.parsefilespec(args.infilename1)
    infilename2, colspec2 = tide_io.parsefilespec(args.infilename2)
    Fs = args.samplerate

    inputdata1 = np.transpose(tide_io.readvecs(infilename1, colspec=colspec1))
    if np.shape(inputdata1)[1] > 1:
        print("specify only one column for input file 1")
        sys.exit()
    else:
        inputdata1 = inputdata1[:, 0]
    inputdata2 = np.transpose(tide_io.readvecs(infilename2, colspec=colspec2))
    if np.shape(inputdata2)[1] > 1:
        print("specify only one column for input file 2")
        sys.exit()
    else:
        inputdata2 = inputdata2[:, 0]

    if args.debug:
        dumpfiltered = True
    else:
        dumpfiltered = False
    showpearson = True

    print("startpoint, endpoint:", args.startpoint, args.endpoint)
    print("thetime:", args.startpoint / Fs)

    startpoint1 = np.max([int(args.startpoint / Fs), 0])
    if args.debug:
        print("startpoint set to ", startpoint1)
    endpoint1 = np.min([int(args.endpoint / Fs), int(len(inputdata1))])
    if args.debug:
        print("endpoint set to ", endpoint1)
    endpoint2 = np.min(
        [int(args.endpoint / Fs), int(len(inputdata1)), int(len(inputdata2))]
    )
    trimdata1 = inputdata1[startpoint1:endpoint1]
    trimdata2 = inputdata2[0:endpoint2]

    if args.trimdata:
        minlen = np.min([len(trimdata1), len(trimdata2)])
        trimdata1 = trimdata1[0:minlen]
        trimdata2 = trimdata2[0:minlen]

    if args.invert:
        flipfac = -1.0
    else:
        flipfac = 1.0

    # band limit the regressor if that is needed
    if theprefilter.gettype() != "None":
        if args.verbose:
            print("filtering to ", theprefilter.gettype(), " band")
    filtereddata1 = tide_math.corrnormalize(
        theprefilter.apply(Fs, trimdata1),
        detrendorder=args.detrendorder,
        windowfunc=args.windowfunc,
    )
    filtereddata2 = tide_math.corrnormalize(
        theprefilter.apply(Fs, trimdata2),
        detrendorder=args.detrendorder,
        windowfunc=args.windowfunc,
    )
    filtereddata2 *= flipfac
    if dumpfiltered:
        tide_io.writenpvecs(filtereddata1, "filtereddata1.txt")
        tide_io.writenpvecs(filtereddata2, "filtereddata2.txt")

    if args.controlvariablefile is not None:
        controlvars = tide_io.readnpvecs(controlvariablefile)
        regressorvec = []
        for j in range(0, numregressors):
            regressorvec.append(
                tide_math.corrnormalize(
                    theprefilter.apply(Fs, controlvars[j, :]),
                    detrendorder=args.detrendorder,
                    windowfunc=args.windowfunc,
                )
            )
        if (np.max(filtereddata1) - np.min(filtereddata1)) > 0.0:
            thefit, filtereddata1 = tide_fit.mlregress(regressorvec, filtereddata1)
        if (np.max(filtereddata2) - np.min(filtereddata2)) > 0.0:
            thefit, filtereddata2 = tide_fit.mlregress(regressorvec, filtereddata2)

    # initialize the correlator
    thecorrelator = tide_classes.correlator(
        Fs=Fs,
        ncprefilter=theprefilter,
        detrendorder=args.detrendorder,
        windowfunc=args.windowfunc,
        corrweighting=args.corrweighting,
    )
    thecorrelator.setreftc(trimdata2 * flipfac)
    themutualinformationator = tide_classes.mutualinformationator(
        Fs=Fs,
        smoothingtime=args.smoothingtime,
        ncprefilter=theprefilter,
        detrendorder=args.detrendorder,
        norm=args.minorm,
        windowfunc=args.windowfunc,
    )
    themutualinformationator.setreftc(trimdata2 * flipfac)

    # do the correlation
    thexcorr, xcorr_x, globalmax = thecorrelator.run(trimdata1, trim=False)
    print("correlator lengths (x, y):", len(xcorr_x), len(thexcorr))
    if dumpfiltered:
        tide_io.writenpvecs(thecorrelator.preptesttc, "correlator_filtereddata1.txt")
        tide_io.writenpvecs(thecorrelator.prepreftc, "correlator_filtereddata2.txt")
    thecorrelator.setlimits(
        int((-args.lagmin * Fs) - 0.5), int((args.lagmax * Fs) + 0.5)
    )
    thexcorr_trim, xcorr_x_trim, dummy = thecorrelator.getfunction(trim=True)
    print("trimmed correlator lengths (x, y):", len(xcorr_x_trim), len(thexcorr_trim))

    # calculate the MI
    theMI, MI_x, globalmax = themutualinformationator.run(
        trimdata1, trim=False, gettimeaxis=True
    )
    print("mutualinformationator lengths (x, y):", len(MI_x), len(theMI))
    if dumpfiltered:
        tide_io.writenpvecs(themutualinformationator.preptesttc, "MI_filtereddata1.txt")
        tide_io.writenpvecs(themutualinformationator.prepreftc, "MI_filtereddata2.txt")
    themutualinformationator.setlimits(
        int((-args.lagmin * Fs) - 0.5), int((args.lagmax * Fs) + 0.5)
    )
    theMI_trim, MI_x_trim, globalmax = themutualinformationator.getfunction(trim=True)
    print(
        "trimmed mutualinformationator lengths (x, y):", len(MI_x_trim), len(theMI_trim)
    )

    if args.cepstral:
        cepdelay = tide_corr.cepstraldelay(
            filtereddata1, filtereddata2, 1.0 / Fs, displayplots=display
        )
        cepcoff = tide_corr.delayedcorr(
            filtereddata1, filtereddata2, cepdelay, 1.0 / Fs
        )
        print("cepstral delay time is", cepdelay, ", correlation is", cepcoff)
    thepxcorr = pearsonr(filtereddata1, filtereddata2)

    # calculate the coherence
    f, Cxy = sp.signal.coherence(
        tide_math.corrnormalize(
            theprefilter.apply(Fs, trimdata1),
            detrendorder=args.detrendorder,
            windowfunc=args.windowfunc,
        ),
        tide_math.corrnormalize(
            theprefilter.apply(Fs, trimdata2),
            detrendorder=args.detrendorder,
            windowfunc=args.windowfunc,
        ),
        Fs,
    )

    # calculate the cross spectral density
    f, Pxy = sp.signal.csd(
        tide_math.corrnormalize(
            theprefilter.apply(Fs, trimdata1),
            detrendorder=args.detrendorder,
            windowfunc=args.windowfunc,
        ),
        tide_math.corrnormalize(
            theprefilter.apply(Fs, trimdata2),
            detrendorder=args.detrendorder,
            windowfunc=args.windowfunc,
        ),
        Fs,
    )

    # intitialize the correlation fitter
    thexsimfuncfitter = tide_classes.simfunc_fitter(
        corrtimeaxis=xcorr_x,
        lagmin=args.lagmin,
        lagmax=args.lagmax,
        absmaxsigma=absmaxsigma,
        absminsigma=absminsigma,
        debug=args.debug,
        peakfittype=peakfittype,
        functype="correlation",
        zerooutbadfit=zerooutbadfit,
        useguess=False,
    )
    # intitialize the correlation fitter
    themifitter = tide_classes.simfunc_fitter(
        corrtimeaxis=MI_x_trim,
        lagmin=args.lagmin,
        lagmax=args.lagmax,
        absmaxsigma=absmaxsigma,
        absminsigma=absminsigma,
        debug=args.debug,
        peakfittype="quad",
        functype="mutualinfo",
        zerooutbadfit=zerooutbadfit,
        useguess=False,
    )

    if args.debug:
        print(
            "searching for peak correlation over range ",
            thecorrelator.similarityfuncorigin - thecorrelator.lagmininpts,
            thecorrelator.similarityfuncorigin + thecorrelator.lagmaxinpts,
        )
    maxdelay = xcorr_x_trim[np.argmax(thexcorr_trim)]
    if args.debug:
        print("\n\nmaxdelay before refinement", maxdelay)

    timeaxis = np.linspace(0, 1.0, num=len(trimdata1), endpoint=False) / Fs
    thetc = trimdata1 * 0.0
    dummy, thepeaks = tide_peakeval._procOneVoxelPeaks(
        0,
        thetc,
        themutualinformationator,
        timeaxis,
        trimdata1,
        timeaxis,
        xcorr_x,
        thexcorr,
        oversampfactor=1,
    )

    print("peaklist:")
    print('peak\tloc\tR\tMI\t"R"')
    for i in range(len(thepeaks)):
        print(
            "{0:2d}\t{1:3.2f}\t{2:3.2f}\t{3:3.2f}\t{4:3.2f}".format(
                i,
                thepeaks[i][0],
                thepeaks[i][1],
                thepeaks[i][2],
                tide_corr.MI_to_R(thepeaks[i][2]),
            )
        )

    (
        maxindex,
        maxdelay,
        maxval,
        maxsigma,
        maskval,
        failreason,
        peakstart,
        peakend,
    ) = thexsimfuncfitter.fit(thexcorr)
    if failreason > 0:
        print("showxcorrx: FIT FAILED with reason:")
        print(thexsimfuncfitter.diagnosefail(np.uint32(failreason)))
    if args.debug:
        print(maxindex, maxdelay, maxval, maxsigma, maskval, failreason)
    R = maxval
    if args.debug:
        print("maxdelay after refinement", maxdelay)

    maxdelaymi = xcorr_x_trim[np.argmax(thexcorr_trim)]
    if args.debug:
        print("\n\nmaxdelaymi before refinement", maxdelaymi)
    (
        maxindexmi,
        maxdelaymi,
        maxvalmi,
        maxsigmami,
        maskvalmi,
        failreasonmi,
        peakstartmi,
        peakendmi,
    ) = themifitter.fit(theMI_trim)
    if failreasonmi > 0:
        print("showxcorrx: FIT FAILED for mutual information with reason:")
        print(themifitter.diagnosefail(np.uint32(failreasonmi)))
    if args.debug:
        print(
            maxindexmi,
            maxdelaymi,
            maxvalmi,
            maxsigmami,
            maskvalmi,
            failreasonmi,
            peakstartmi,
            peakendmi,
        )
    R = maxval
    if args.debug:
        print("maxdelay after refinement", maxdelay, "\n\n")

    # set the significance threshold
    if args.numestreps > 0:
        # generate a list of correlations from shuffled data
        print("calculating null crosscorrelations")
        corrlist = tide_nullsimfunc.getNullDistributionDatax(
            filtereddata2,
            Fs,
            thecorrelator,
            thexsimfuncfitter,
            numestreps=args.numestreps,
            despeckle_thresh=1000.0,
            showprogressbar=args.showprogressbar,
            permutationmethod=args.permutationmethod,
            nprocs=args.nprocs,
            fixdelay=False,
        )

        # calculate percentiles for the crosscorrelation from the distribution data
        histlen = 100
        thepercentiles = [0.95, 0.99, 0.995]

        pcts, pcts_fit, histfit = tide_stats.sigFromDistributionData(
            corrlist, histlen, thepercentiles
        )
        if args.debug:
            tide_stats.printthresholds(
                pcts,
                thepercentiles,
                "Crosscorrelation significance thresholds from data:",
            )
            tide_stats.printthresholds(
                pcts_fit,
                thepercentiles,
                "Crosscorrelation significance thresholds from fit:",
            )

        print("calculating null Pearson correlations")
        corrlist_pear = tide_nullsimfunc.getNullDistributionDatax(
            filtereddata2,
            Fs,
            thecorrelator,
            thexsimfuncfitter,
            numestreps=args.numestreps,
            despeckle_thresh=1000.0,
            showprogressbar=args.showprogressbar,
            permutationmethod=args.permutationmethod,
            nprocs=args.nprocs,
            fixdelay=True,
        )

        # calculate significance for the pearson correlation
        pearpcts, pearpcts_fit, histfit = tide_stats.sigFromDistributionData(
            corrlist_pear, histlen, thepercentiles
        )
        if args.debug:
            tide_stats.printthresholds(
                pearpcts,
                thepercentiles,
                "Pearson correlation significance thresholds from data:",
            )
            tide_stats.printthresholds(
                pearpcts_fit,
                thepercentiles,
                "Pearson correlation significance thresholds from fit:",
            )

        if args.debug:
            tide_io.writenpvecs(corrlist, "corrlist.txt")
            tide_io.writenpvecs(corrlist_pear, "corrlist_pear.txt")

    if args.debug:
        print(thepxcorr)

    if args.summarymode:
        if args.numestreps > 0:
            thelabelitems = [
                "pearson_R",
                "pearson_R(p=0.05)",
                "xcorr_R",
                "xcorr_R(p=0.05)",
                "xcorr_maxdelay",
            ]
            thedataitems = [
                str(thepxcorr[0]),
                str(pearpcts_fit[0]),
                str(R),
                str(pcts_fit[0]),
                str(-maxdelay),
            ]
        else:
            thelabelitems = ["pearson_R", "pearson_p", "xcorr_R", "xcorr_maxdelay"]
            thedataitems = [
                str(thepxcorr[0]),
                str(thepxcorr[1]),
                str(R),
                str(-maxdelay),
            ]
        if args.label is not None:
            thelabelitems = ["thelabel"] + thelabelitems
            thedataitems = [args.label] + thedataitems
        if args.labelline:
            outputstring = "\t".join(thelabelitems) + "\n" + "\t".join(thedataitems)
        else:
            outputstring = "\t".join(thedataitems)
        if args.outputfile is None:
            print(outputstring)
        else:
            with open(args.outputfile, "w") as text_file:
                text_file.write(outputstring + "\n")
    else:
        # report the pearson correlation
        if showpearson:
            print("Pearson_R:\t", thepxcorr[0])
            if args.numestreps > 0:
                for idx, percentile in enumerate(thepercentiles):
                    print(
                        "    pear_p(",
                        "{:.3f}".format(1.0 - percentile),
                        "):\t",
                        pearpcts[idx],
                    )
            print("")
        if args.label is not None:
            print(args.label, ":\t", -maxdelay)
        else:
            print("Crosscorrelation_Rmax:\t", R)
            print("Crosscorrelation_maxdelay:\t", -maxdelay)
            if args.numestreps > 0:
                for idx, percentile in enumerate(thepercentiles):
                    print(
                        "    xc_p(",
                        "{:.3f}".format(1.0 - percentile),
                        "):\t",
                        pcts[idx],
                    )
            print(
                infilename1, "[0 seconds] == ", infilename2, "[", -maxdelay, " seconds]"
            )

    if args.display:
        fig = figure()
        ax = fig.add_subplot(111)
        ax.set_title("Similarity metrics over the search range")
        ax.plot(xcorr_x_trim, thexcorr_trim, "k")
        # print(xcorr_x_trim)
        ax.plot(MI_x_trim, theMI_trim, "r")
        ax.legend(["Cross correlation", "Mutual Information"])
        # print(MI_x_trim)
        if args.debug:
            fig = figure()
            plot(f, Cxy)
            fig = figure()
            plot(f, np.sqrt(np.abs(Pxy)) / np.max(np.sqrt(np.abs(Pxy))))
            plot(f, np.angle(Pxy) / (2.0 * sp.pi * f))
        show()

    if args.corroutputfile is not None:
        tide_io.writenpvecs(np.stack((xcorr_x, thexcorr), axis=0), args.corroutputfile)
    if args.debug:
        tide_io.writenpvecs(np.stack((MI_x_trim, theMI_trim), axis=0), "mifunc.txt")


if __name__ == "__main__":
    main()
